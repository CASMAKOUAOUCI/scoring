{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P7_02_code_export_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foc6pLvavZrx"
      },
      "source": [
        "**Accueil Risque de défaut de crédit Concurrence**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkXZkxnV6Va3"
      },
      "source": [
        "#**Importation les données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGue0vu03ykf"
      },
      "source": [
        "Nous utilisons une pile typique de science des données : numpy, pandas, sklearn, matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKZJyDehvUK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989af27c-44b9-4e55-bcf0-a808afbe668b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVwl4S_mbZXq"
      },
      "source": [
        "#Imports libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, warnings, csv, pickle\n",
        "warnings.filterwarnings('ignore')\n",
        "from joblib import dump, load\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O_Aajs3be-B",
        "outputId": "7e02db47-3a3d-4b2c-975f-8ef15defeeea"
      },
      "source": [
        "# Import data set\n",
        "path =\"/content/drive/MyDrive/Data.Projet3/Projet7/Projet+credit/\"\n",
        "\n",
        "app_train = pd.read_csv(path + \"application_train.csv\", index_col = \"SK_ID_CURR\")\n",
        "print('Training data shape: ', app_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (307511, 121)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22RSkofWb7ak"
      },
      "source": [
        "app_train['AGE'] = (app_train['DAYS_BIRTH']/-365).astype('int64')\n",
        "app_train['DAYS_EMPLOYED'].replace({365243: 0}, inplace = True)\n",
        "app_train['YEARS_EMPLOYED'] = round((app_train['DAYS_EMPLOYED']/-365).astype('int64'), 0)\n",
        "app_train['YEARS_EMPLOYED_PERCENT'] = app_train['YEARS_EMPLOYED'] / app_train['AGE']\n",
        "app_train.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)\n",
        "\n",
        "app_train[\"CREDIT_ANNUITY_RATIO\"] = app_train[\"AMT_CREDIT\"] / app_train[\"AMT_ANNUITY\"]\n",
        "app_train[\"INCOME_ANNUITY_RATIO\"] = app_train[\"AMT_INCOME_TOTAL\"] / app_train[\"AMT_ANNUITY\"]\n",
        "app_train[\"INCOME_CREDIT_RATIO\"] = app_train[\"AMT_INCOME_TOTAL\"] / app_train[\"AMT_CREDIT\"]\n",
        "app_train[\"CREDIT_GOODS_PRICE_RATIO\"] = app_train[\"AMT_CREDIT\"] / app_train[\"AMT_GOODS_PRICE\"]\n",
        "app_train[\"CREDIT_DOWNPAYMENT\"] = app_train[\"AMT_GOODS_PRICE\"] / app_train[\"AMT_CREDIT\"]\n",
        "app_train[\"CREDIT_INCOME_PERCENT\"] = app_train[\"AMT_CREDIT\"] / app_train[\"AMT_INCOME_TOTAL\"]\n",
        "app_train[\"ANNUITY_INCOME_PERCENT\"] = app_train[\"AMT_ANNUITY\"] / app_train[\"AMT_INCOME_TOTAL\"]\n",
        "app_train[\"RATIO_CREDIT_GOODS_PRICE\"] = app_train[\"AMT_CREDIT\"] / app_train[\"AMT_GOODS_PRICE\"]\n",
        "app_train[\"DIFF_GOODS_PRICE_CREDIT\"] = app_train[\"AMT_CREDIT\"] - app_train[\"AMT_GOODS_PRICE\"]\n",
        "app_train['CREDIT_TERM'] = app_train['AMT_ANNUITY'] / app_train['AMT_CREDIT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uVH-dYjcDES"
      },
      "source": [
        "def sampling(df, sample_size):\n",
        "    df = df.copy()\n",
        "    print('la taill de dataset initial : ', df.shape)\n",
        "    df = df.reset_index(drop = True)\n",
        "    df_sample0 = df[df['TARGET'] == 0]\n",
        "    df_sample1 = df[df['TARGET'] == 1]\n",
        "    n0 = round(len(df_sample0)*sample_size)\n",
        "    n1 = round(len(df_sample1)*sample_size)\n",
        "    print('le nombre de lignes de df_sample0: ', n0)\n",
        "    print('le nombre de lignes de df_sample1: ', n1)\n",
        "\n",
        "    df_sample0 = df_sample0.sample(n = n0)\n",
        "    df_sample1 = df_sample1.sample(n = n1)\n",
        "\n",
        "    df_sample = pd.concat([df_sample0, df_sample1], axis=0)\n",
        "    df_sample = df_sample.reset_index(drop=True)\n",
        "    print('Random under-sampling:')\n",
        "    print(df_sample.shape)\n",
        "    print(df_sample.TARGET.value_counts())\n",
        "    return df_sample\n",
        "\n",
        "def split_stratified(df, test_size):\n",
        "    X = df.drop(columns = ['TARGET'])\n",
        "    y = df['TARGET']\n",
        "    X = pd.DataFrame(X, columns = X.columns)\n",
        "    sss = StratifiedShuffleSplit(n_splits=2, test_size=test_size, random_state=0)\n",
        "    sss.get_n_splits(X, y)\n",
        "    for train_index, test_index in sss.split(X, y):        \n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    return X_train, X_test, y_train, y_test\n",
        "X_train, X_test, y_train, y_test = split_stratified(app_train, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKDUNK1RcJfw"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(app_train.drop(columns = ['TARGET']), app_train['TARGET'], test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIoHUKDHcJdc"
      },
      "source": [
        "#FEATURES\n",
        "col_qunti = sorted(list(set(app_train.select_dtypes('float64').columns).union(set(app_train.select_dtypes('int64').columns))))\n",
        "col_qunti.remove(\"TARGET\")\n",
        "\n",
        "poly_features = sorted(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AGE'])\n",
        "\n",
        "col_qunti_except_poly = [x for x in col_qunti if x not in poly_features]\n",
        "\n",
        "col_category = sorted(list(set(app_train.select_dtypes('object').columns)))\n",
        "label_encode_features = sorted([\"NAME_CONTRACT_TYPE\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\"])\n",
        "one_hot_encode_features = sorted(list(set(col_category)-set(label_encode_features)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZk3njGHcJa1"
      },
      "source": [
        "#preprocessor_dashboard\n",
        "quanti_processor_dashboard = Pipeline(steps=[('impute_quanti', SimpleImputer(missing_values = np.nan,\n",
        "                                                                                 strategy='median'))])\n",
        "category_preprocessor_dashboard = Pipeline(steps=[('impute_category', SimpleImputer(missing_values = np.nan,\n",
        "                                                                                    strategy = \"constant\",\n",
        "                                                                                    fill_value = \"NC\"))])\n",
        "preprocessor_dashboard = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('quanti_processor', quanti_processor_dashboard, col_qunti),\n",
        "        ('category_processor', category_preprocessor_dashboard, col_category)\n",
        "    ], verbose = False)\n",
        "\n",
        "pretraitement_dashboard = Pipeline(steps=[('preprocessor', preprocessor_dashboard)])\n",
        "#col_name for dataframe - dashboard\n",
        "dashboard_col_name = [*col_qunti, *col_category]\n",
        "with open('dashboard_col_name.pkl', 'wb') as f:\n",
        "    pickle.dump(dashboard_col_name, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47t73FqlcJYX",
        "outputId": "9b54f291-19ec-4c06-a98f-26f649e3ff04"
      },
      "source": [
        "X_train = X_train[dashboard_col_name]\n",
        "pretraitement_dashboard.fit(X_train, y_train)\n",
        "dump(pretraitement_dashboard, 'pretraitement_dashboard.joblib')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pretraitement_dashboard.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG9ektNPcZxX"
      },
      "source": [
        "#preprocessor_prediction\n",
        "quanti_processor_prediction = Pipeline(steps=[('impute_quanti', SimpleImputer(missing_values = np.nan,\n",
        "                                                                                  strategy='median')),\n",
        "                                              ('standard', MinMaxScaler(feature_range = (0, 1)))])\n",
        "poly_processor = Pipeline(steps=[('impute_quanti', SimpleImputer(missing_values = np.nan,\n",
        "                                                                     strategy='median')),\n",
        "                                 ('polynomial', PolynomialFeatures(degree = 3))])\n",
        "label_encode_preprocessor = Pipeline(steps=[('impute_category', SimpleImputer(missing_values = np.nan,\n",
        "                                                                              strategy = \"constant\",\n",
        "                                                                              fill_value = \"NC\")),\n",
        "                                            ('label_encode', OrdinalEncoder())])\n",
        "one_hot_encode_preprocessor = Pipeline(steps=[('impute_category', SimpleImputer(missing_values = np.nan,\n",
        "                                                                                strategy = \"constant\",\n",
        "                                                                                fill_value = \"NC\")),\n",
        "                                              ('one_hot_encode', OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor_prediction = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('quanti_processor', quanti_processor_prediction, col_qunti_except_poly),\n",
        "        ('poly_processor', poly_processor, poly_features), \n",
        "        ('label_encode_processor', label_encode_preprocessor, label_encode_features),\n",
        "        ('one_hot_encode_processor', one_hot_encode_preprocessor, one_hot_encode_features)\n",
        "    ], verbose = False)\n",
        "\n",
        "pretraitement_prediction = Pipeline(steps=[('preprocessor', preprocessor_prediction)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRNHmyS8cdX0"
      },
      "source": [
        "pretraitement_prediction.fit(X_train, y_train)\n",
        "dump(pretraitement_prediction, 'pretraitement_prediction.joblib')\n",
        "#col_name for dataframe - prediction\n",
        "poly_col = pretraitement_prediction.named_steps['preprocessor'].transformers_[1][1].named_steps['polynomial'].get_feature_names(poly_features)\n",
        "one_hot_encode_col = pretraitement_prediction.named_steps['preprocessor'].transformers_[3][1].named_steps['one_hot_encode'].get_feature_names(one_hot_encode_features)\n",
        "col_name = [*col_qunti_except_poly, *poly_col, *label_encode_features, *one_hot_encode_col]\n",
        "with open('col_name_list.pkl', 'wb') as f:\n",
        "    pickle.dump(col_name, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlpeFObXcfco",
        "outputId": "eae58576-5edf-483c-9a25-c799673e7642"
      },
      "source": [
        "model = Pipeline(steps=[('classifier', LogisticRegression(max_iter=1000,\n",
        "                                                          solver='sag',\n",
        "                                                          multi_class = 'ovr',\n",
        "                                                          class_weight='balanced',\n",
        "                                                          C = 0.1,\n",
        "                                                          penalty = \"l2\"))])\n",
        "X_train_prediction = pretraitement_prediction.fit_transform(X_train, y_train)\n",
        "model.fit(X_train_prediction, y_train)\n",
        "dump(model, 'model.joblib')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2qPjNlpcfZ7"
      },
      "source": [
        "sample_data = app_train.iloc[0:2500, :]\n",
        "sample_data.to_csv('sample_data.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}